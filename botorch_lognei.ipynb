{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae39d705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonghyun\\anaconda3\\envs\\boenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.6.0+cu124\n",
      "BoTorch: 0.15.1\n",
      "GPyTorch: 1.14\n",
      "qLogNoisyExpectedImprovement import OK\n"
     ]
    }
   ],
   "source": [
    "import torch, botorch, gpytorch\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"BoTorch:\", botorch.__version__)\n",
    "print(\"GPyTorch:\", gpytorch.__version__)\n",
    "from botorch.acquisition.logei import qLogNoisyExpectedImprovement\n",
    "print(\"qLogNoisyExpectedImprovement import OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "695d0920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.2-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\jonghyun\\anaconda3\\envs\\boenv\\lib\\site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jonghyun\\anaconda3\\envs\\boenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jonghyun\\anaconda3\\envs\\boenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.2-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.4/11.3 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.7/11.3 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.3/11.3 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.7/11.3 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 11.4 MB/s  0:00:01\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   ---------------------------------------- 3/3 [pandas]\n",
      "\n",
      "Successfully installed pandas-2.3.2 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf921a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bo_lognei_latest.py\n",
    "import os, sys, csv\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "# ---- BoTorch / GPyTorch ----\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Standardize, Normalize\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "from botorch.acquisition.monte_carlo import qUpperConfidenceBound\n",
    "from botorch.acquisition.logei import qLogNoisyExpectedImprovement\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.optim import optimize_acqf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df0d2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# User Config (EDIT HERE)\n",
    "# =========================\n",
    "SEED = 123\n",
    "MAX_ITERS = 20                 # 총 이터레이션 수\n",
    "N_RANDOM = 5                   # 초기 랜덤 탐색 이터레이션\n",
    "N_UCB = 5                      # 그 다음 UCB 이터레이션\n",
    "UCB_BETA = 0.25                # qUCB beta\n",
    "OBJECTIVE_SENSE = \"min\"        # \"min\" or \"max\"\n",
    "LOG_CSV = \"bo_log.csv\"         # 로그 파일 경로\n",
    "\n",
    "# 파라미터 범위 (예시) → 네 범위로 수정\n",
    "PBONDS: Dict[str, Tuple[float, float]] = {\n",
    "    \"pressure\"     : (250.0, 450.0),\n",
    "    \"velocity\"     : (2.0, 40.0),\n",
    "    \"wall_spacing\" : (0.20, 1.00),\n",
    "    \"layer_spacing\": (0.10, 0.60),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a255ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "torch.manual_seed(SEED)\n",
    "tkwargs = {\"dtype\": torch.double, \"device\": \"cpu\"}\n",
    "\n",
    "PARAMS = list(PBONDS.keys())\n",
    "LB = torch.tensor([PBONDS[p][0] for p in PARAMS], **tkwargs)\n",
    "UB = torch.tensor([PBONDS[p][1] for p in PARAMS], **tkwargs)\n",
    "BOUNDS = torch.stack([LB, UB])  # shape [2, d]\n",
    "D = len(PARAMS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67f081c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_csv(path: str):\n",
    "    \"\"\"Create CSV with header if missing.\"\"\"\n",
    "    if not Path(path).exists():\n",
    "        with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            w = csv.writer(f)\n",
    "            header = [\"iter\", \"timestamp\"] + PARAMS + [\n",
    "                \"objective_raw\", \"objective_for_BO\", \"acquisition\"\n",
    "            ]\n",
    "            w.writerow(header)\n",
    "\n",
    "\n",
    "def log_row(path: str, iteration: int, x: Tensor, y_raw: float, y_bo: float, acq_name: str):\n",
    "    \"\"\"Append one row to CSV.\"\"\"\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    x_list = [float(v) for v in x.view(-1).tolist()]\n",
    "    row = [iteration, ts] + x_list + [float(y_raw), float(y_bo), acq_name]\n",
    "    with open(path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        csv.writer(f).writerow(row)\n",
    "\n",
    "\n",
    "def sample_random(n: int = 1) -> Tensor:\n",
    "    \"\"\"Uniform random sample within bounds.\"\"\"\n",
    "    u = torch.rand(n, D, **tkwargs)\n",
    "    return LB + (UB - LB) * u\n",
    "\n",
    "\n",
    "def ask_user_evaluate(x: Tensor) -> float:\n",
    "    \"\"\"Print x and ask user for objective value.\"\"\"\n",
    "    print(\"\\n--- Evaluate Candidate ---\")\n",
    "    for i, p in enumerate(PARAMS):\n",
    "        print(f\"{p:>14s} : {float(x[i]):.6g}\")\n",
    "    while True:\n",
    "        s = input(\"Enter objective value (float): \").strip()\n",
    "        try:\n",
    "            return float(s)\n",
    "        except ValueError:\n",
    "            print(\"⚠️  Not a float. Try again.\")\n",
    "\n",
    "\n",
    "def y_for_bo(y_raw: float) -> float:\n",
    "    \"\"\"Convert raw objective to 'maximize' convention for BoTorch.\"\"\"\n",
    "    if OBJECTIVE_SENSE.lower().startswith(\"min\"):\n",
    "        return -float(y_raw)  # minimize → maximize by sign flip\n",
    "    return float(y_raw)\n",
    "\n",
    "\n",
    "def fit_model(train_X: Tensor, train_Y: Tensor) -> SingleTaskGP:\n",
    "    \"\"\"Fit SingleTaskGP with normalization/standardization.\"\"\"\n",
    "    model = SingleTaskGP(\n",
    "        train_X,\n",
    "        train_Y,\n",
    "        input_transform=Normalize(d=D),\n",
    "        outcome_transform=Standardize(m=1),\n",
    "    )\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    return model\n",
    "\n",
    "\n",
    "def next_via_ucb(model: SingleTaskGP, q: int = 1) -> Tensor:\n",
    "    sampler = SobolQMCNormalSampler(sample_shape=torch.Size([512]))\n",
    "    acq = qUpperConfidenceBound(model, beta=UCB_BETA, sampler=sampler)\n",
    "    cand, _ = optimize_acqf(\n",
    "        acq_function=acq,\n",
    "        bounds=BOUNDS,\n",
    "        q=q,\n",
    "        num_restarts=10,\n",
    "        raw_samples=256,\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "    )\n",
    "    return cand.detach()\n",
    "\n",
    "\n",
    "def next_via_lognei(model: SingleTaskGP, train_X: Tensor, train_Y: Tensor, q: int = 1) -> Tensor:\n",
    "    sampler = SobolQMCNormalSampler(sample_shape=torch.Size([1024]))\n",
    "    acq = qLogNoisyExpectedImprovement(\n",
    "        model=model,\n",
    "        X_baseline=train_X,\n",
    "        sampler=sampler,\n",
    "    )\n",
    "    cand, _ = optimize_acqf(\n",
    "        acq_function=acq,\n",
    "        bounds=BOUNDS,\n",
    "        q=q,\n",
    "        num_restarts=15,\n",
    "        raw_samples=256,\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "    )\n",
    "    return cand.detach()\n",
    "\n",
    "\n",
    "def tensorize_logs(path: str) -> Tuple[Optional[Tensor], Optional[Tensor]]:\n",
    "    \"\"\"Load existing CSV (if any) to X,Y tensors for warm start.\"\"\"\n",
    "    if not Path(path).exists():\n",
    "        return None, None\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(path)\n",
    "    if df.empty:\n",
    "        return None, None\n",
    "    X = torch.tensor(df[PARAMS].values, **tkwargs)\n",
    "    Y_bo = torch.tensor(df[\"objective_for_BO\"].values.reshape(-1, 1), **tkwargs)\n",
    "    return X, Y_bo\n",
    "\n",
    "\n",
    "def main():\n",
    "    ensure_csv(LOG_CSV)\n",
    "\n",
    "    # Warm-start from existing log (optional)\n",
    "    X_all, Y_all = tensorize_logs(LOG_CSV)\n",
    "    if X_all is None:\n",
    "        X_all = torch.empty(0, D, **tkwargs)\n",
    "        Y_all = torch.empty(0, 1, **tkwargs)\n",
    "        iter_start = 1\n",
    "    else:\n",
    "        iter_start = int(X_all.shape[0]) + 1\n",
    "        print(f\"✅ Resuming from {LOG_CSV}: {iter_start-1} rows loaded.\")\n",
    "\n",
    "    # BO Loop\n",
    "    for it in range(iter_start, MAX_ITERS + 1):\n",
    "        if it <= N_RANDOM:\n",
    "            acq_name = \"RANDOM\"\n",
    "            x_next = sample_random(1).squeeze(0)\n",
    "        else:\n",
    "            # need at least 2 points to fit GP sensibly\n",
    "            if X_all.shape[0] < 2:\n",
    "                x_next = sample_random(1).squeeze(0)\n",
    "                acq_name = \"RANDOM\"\n",
    "            else:\n",
    "                # Fit model on current data\n",
    "                try:\n",
    "                    model = fit_model(X_all, Y_all)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ GP fit failed ({e}). Fallback to RANDOM.\")\n",
    "                    x_next = sample_random(1).squeeze(0)\n",
    "                    acq_name = \"RANDOM\"\n",
    "                else:\n",
    "                    if it <= N_RANDOM + N_UCB:\n",
    "                        acq_name = f\"qUCB(beta={UCB_BETA})\"\n",
    "                        x_next = next_via_ucb(model).squeeze(0)\n",
    "                    else:\n",
    "                        acq_name = \"qLogNEI\"\n",
    "                        x_next = next_via_lognei(model, X_all, Y_all).squeeze(0)\n",
    "\n",
    "        # Evaluate (user input)\n",
    "        y_raw = ask_user_evaluate(x_next)\n",
    "        y_bo = y_for_bo(y_raw)\n",
    "\n",
    "        # Update data\n",
    "        X_all = torch.cat([X_all, x_next.view(1, -1)], dim=0)\n",
    "        Y_all = torch.cat([Y_all, torch.tensor([[y_bo]], **tkwargs)], dim=0)\n",
    "\n",
    "        # Log to CSV\n",
    "        log_row(LOG_CSV, it, x_next, y_raw, y_bo, acq_name)\n",
    "        print(f\"📎 Logged iter {it} ({acq_name}) → raw={y_raw:.6g}  for_BO={y_bo:.6g}\")\n",
    "\n",
    "    print(\"\\n🎉 BO finished.\")\n",
    "    print(f\"Log saved to: {Path(LOG_CSV).resolve()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de371fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resuming from bo_log.csv: 5 rows loaded.\n",
      "\n",
      "--- Evaluate Candidate ---\n",
      "      pressure : 329.859\n",
      "      velocity : 2\n",
      "  wall_spacing : 0.579741\n",
      " layer_spacing : 0.221724\n",
      "Enter objective value (float): 15\n",
      "📎 Logged iter 6 (qUCB(beta=0.25)) → raw=15  for_BO=-15\n",
      "\n",
      "--- Evaluate Candidate ---\n",
      "      pressure : 316.871\n",
      "      velocity : 2\n",
      "  wall_spacing : 0.68267\n",
      " layer_spacing : 0.136228\n",
      "Enter objective value (float): 13\n",
      "📎 Logged iter 7 (qUCB(beta=0.25)) → raw=13  for_BO=-13\n",
      "\n",
      "--- Evaluate Candidate ---\n",
      "      pressure : 319.246\n",
      "      velocity : 2.62905\n",
      "  wall_spacing : 0.655137\n",
      " layer_spacing : 0.151644\n",
      "Enter objective value (float): 12\n",
      "📎 Logged iter 8 (qUCB(beta=0.25)) → raw=12  for_BO=-12\n",
      "\n",
      "--- Evaluate Candidate ---\n",
      "      pressure : 368.86\n",
      "      velocity : 3.33691\n",
      "  wall_spacing : 0.727375\n",
      " layer_spacing : 0.145501\n",
      "Enter objective value (float): 13\n",
      "📎 Logged iter 9 (qUCB(beta=0.25)) → raw=13  for_BO=-13\n",
      "\n",
      "--- Evaluate Candidate ---\n",
      "      pressure : 450\n",
      "      velocity : 4.44424\n",
      "  wall_spacing : 0.914087\n",
      " layer_spacing : 0.147454\n",
      "Enter objective value (float): 15\n",
      "📎 Logged iter 10 (qUCB(beta=0.25)) → raw=15  for_BO=-15\n",
      "\n",
      "--- Evaluate Candidate ---\n",
      "      pressure : 333.858\n",
      "      velocity : 2.75979\n",
      "  wall_spacing : 0.684816\n",
      " layer_spacing : 0.148003\n",
      "Enter objective value (float): 16\n",
      "📎 Logged iter 11 (qLogNEI) → raw=16  for_BO=-16\n",
      "\n",
      "--- Evaluate Candidate ---\n",
      "      pressure : 434.888\n",
      "      velocity : 2\n",
      "  wall_spacing : 0.383335\n",
      " layer_spacing : 0.121512\n",
      "Enter objective value (float): 12\n",
      "📎 Logged iter 12 (qLogNEI) → raw=12  for_BO=-12\n",
      "\n",
      "--- Evaluate Candidate ---\n",
      "      pressure : 250\n",
      "      velocity : 2.16295\n",
      "  wall_spacing : 0.292873\n",
      " layer_spacing : 0.1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    main()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nInterrupted by user.\")\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f64f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:boenv]",
   "language": "python",
   "name": "conda-env-boenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
